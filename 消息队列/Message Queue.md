## MQ简介及特点

MQ全称为Message Queue, 消息队列（MQ）是一种应用程序对应用程序的通信方法。

应用程序通过写和检索出入列队的针对应用程序的数据（消息）来通信，而无需专用连接来链接它们。

消息传递指的是程序之间通过在消息队列中发送数据进行通信，而不是通过直接调用彼此来通信，直接调用通常是用于诸如远程过程调用的技术，如RESTFUL API。

## MQ使用场景

### 1、异步通信

有些业务不想也不需要立即处理消息。消息队列提供了异步处理机制，允许用户把一个消息放入队列，但并不立即处理它。想向队列中放入多少消息就放多少，然后在需要的时候再去处理它们。

### 2、解耦

降低工程间的强依赖程度，针对异构系统进行适配。在项目启动之初来预测将来项目会碰到什么需求，是极其困难的。通过消息系统在处理过程中间插入了一个隐含的、基于数据的接口层，两边的处理过程都要实现这一接口，当应用发生变化时，可以独立的扩展或修改两边的处理过程，只要确保它们遵守同样的接口约束。

### 3、冗余

有些情况下，处理数据的过程会失败。除非数据被持久化，否则将造成丢失。消息队列把数据进行持久化直到它们已经被完全处理，通过这一方式规避了数据丢失风险。许多消息队列所采用的"插入-获取-删除"范式中，在把一个消息从队列中删除之前，需要你的处理系统明确的指出该消息已经被处理完毕，从而确保你的数据被安全的保存直到你使用完毕。

### 4、扩展性

因为消息队列解耦了你的处理过程，所以增大消息入队和处理的频率是很容易的，只要另外增加处理过程即可。不需要改变代码、不需要调节参数。便于分布式扩容。

### 5、过载保护

在访问量剧增的情况下，应用仍然需要继续发挥作用，但是这样的突发流量无法提取预知；如果为了能处理这类瞬间峰值访问为标准来投入资源随时待命无疑是巨大的浪费。使用消息队列能够使关键组件顶住突发的访问压力，而不会因为突发的超负荷的请求而完全崩溃。

### 6、可恢复性

系统的一部分组件失效时，不会影响到整个系统。消息队列降低了进程间的耦合度，所以即使一个处理消息的进程挂掉，加入队列中的消息仍然可以在系统恢复后被处理。

### 7、顺序保证

在大多使用场景下，数据处理的顺序都很重要。大部分消息队列本来就是排序的，并且能保证数据会按照特定的顺序来处理。

### 8、缓冲

在任何重要的系统中，都会有需要不同的处理时间的元素。消息队列通过一个缓冲层来帮助任务最高效率的执行，该缓冲有助于控制和优化数据流经过系统的速度。以调节系统响应时间。

###  9、数据流处理 

分布式系统产生的海量数据流，如：业务日志、监控数据、用户行为等，针对这些数据流进行实时或批量采集汇总，然后进行大数据分析是当前互联网的必备技术，通过消息队列完成此类数据收集是最好的选择。

## RabbitMQ

### 1、什么是RabbitMQ？为什么使用RabbitMQ？

RabbitMQ是一款开源的，Erlang编写的，基于**AMQP**协议的消息中间件；可以用它来：解耦、异步、削峰。

### 2、RabbitMQ有什么优缺点？

优点：解耦、异步、削峰；

缺点：降低了系统的稳定性，本来系统运行好好的，现在加入个消息队列进去，那消息队列挂了，系统就崩溃了。因此，系统可用性会降低；同时，消息队列的引入，增加了系统的复杂性，加入了消息队列，**要多考虑很多方面的问题，比如：一致性问题、如何保证消息不被重复消费、如何保证消息可靠性传输等。**

### 3、如何保证RabbitMQ的高可用？

没有哪个项目会只搭建一台RabbitMQ服务器提供服务，风险太大，为了高可用的RabbitMQ服务，需要搭建消息队列集群；

### 4、如何保证RabbitMQ不被重复消费？

先说为什么会重复消费：正常情况下，消费者在消费消息的时候，消费完毕后，会发送一个确认消息给消息队列，消息队列就知道该消息被消费了，就会将该消息从消息队列中删除；但是因为网络传输等等故障，确认信息没有传送到消息队列，导致消息队列不知道自己已经消费过该消息了，再次将消息分发给其他的消费者。

针对以上问题，一个解决思路是：**保证消息的唯一性，就算是多次传输，不要让消息的多次消费带来影响即保证消息等幂性；**

**比如：在写入消息队列的数据做唯一标示，消费消息时，根据唯一标识判断是否消费过；**

### 5、如何保证RabbitMQ消息的可靠传输？

**消息不可靠的情况可能是消息丢失，劫持等原因；**

**丢失又分为：生产者丢失消息、消息列表丢失消息、消费者丢失消息；**

**生产者丢失消息**：从生产者弄丢数据这个角度来看，RabbitMQ提供transaction和confirm两个可选模式来确保生产者不丢消息；

Transaction机制就是说：发送消息前，开启事务（channel.txSelect()）,然后发送消息，如果发送过程中出现什么异常，事务就会回滚（channel.txRollback()), 如果发送成功则提交事务（channel.txCommit()）。**然而，这种方式有个缺点：吞吐量下降；**

Confirm模式用的居多：一旦channel进入confirm模式，所有在该信道上发布的消息都将会被指派一个唯一的ID（从1开始），一旦消息被投递到所有匹配的队列之后；rabbitMQ就会发送一个ACK给生产者（包含消息的唯一ID），这就使得生产者知道消息已经正确到达目的队列了；如果rabbitMQ没能处理该消息，则会发送一个Nack消息给你，你可以进行重试操作。

**消息队列丢数据：消息持久化。**

处理消息队列丢数据的情况，一般是开启持久化磁盘的配置。

这个持久化配置可以和confirm机制配合使用，你可以在消息持久化磁盘后，再给生产者发送一个Ack信号。

这样，如果消息持久化磁盘之前，rabbitMQ阵亡了，那么生产者收不到Ack信号，生产者会自动重发。

那么如何持久化呢？

这里顺便说一下吧，其实也很容易，就下面两步

1. 将queue的持久化标识durable设置为true,则代表是一个持久的队列
2. 发送消息的时候将deliveryMode=2

这样设置以后，即使rabbitMQ挂了，重启后也能恢复数据

 **消费者丢失消息**：消费者丢数据一般是因为采用了自动确认消息模式，改为手动确认消息即可！消费者在收到消息之后，处理消息之前，会自动回复RabbitMQ已收到消息；如果这时处理消息失败，就会丢失该消息；

解决方案：处理消息成功后，手动回复确认消息。

### 6、如何保证RabbitMQ消息的顺序性？

（1）单线程消费保证消息的顺序性；

（2）对消息进行编号，消费者处理消息是根据编号处理消息；

## Kafka

### consumer和producer

消费者主动从broker获取消息，pull模式

broker将消息推送给消费者，push模式

kafka遵循了一种大部分消息系统共同的设计即采用pull模式，生产者将消息推到broker，消费者从broker中拉取消息

好处是消费者不容易崩溃，因为消费者拉取消息的速率是自己决定的，但是对应的缺点就是broker不能决定消息的推送的速率

### kafka维护消费状态跟踪的方法有什么

大部分消息系统在broker端维护消息被消费的记录，一个消息被分发到消费者后broker就马上进行标记或者等待消费者的通知后标记，

问题：

如果一条消息发送出去后就立即被标记为消费过的，我们可以立即想到如果消费者处理消息时失败了，消息就丢失了。如果是等待消费者通知成功消费后才进行标记，解决上述的问题但产生了新的问题。

- 如果消费者消费成功了但是向broker通知过程中失败了，这条消息将被消费两次
- broker必须维护每条消息的状态，并且每次都要先锁住消息然后更改状态后释放锁。这样处理除了维护大量的状态数据外，如果消息发送出去但是没有接收到成功被消费的通知，这条消息就会一直处于被锁定的状态

kafka采用了不同的策略，topic会分成了若干分区，每个分区在同一时间只被一个消费者消费，每个分区消息被消费在日志中通过位移偏移量来记录也就是offset。这就意味着每个分区的消息消费状态用一个简单的整数就搞定了，同时消费者可以通过把offset调成一个较小的老值，去重新消费老的消息。

### zookeeper配合kafka

zookeeper是开源的高性能的分布式系统协调服务，可用于kafka的分布式场景。

在kafka中，它被用于提交偏移量，因此如果有节点失败了，利用zookeeper可以从之前提交的偏移量中获取，除此之外zookeeper还可以进行其他活动，如leader节点检测、分布式同步、配置管理等集群管理。

### kafka如何判断一个节点是否处于正常工作状态：

- 节点必须保持和zookeeper的连接，zookeeper通过心跳机制检查每个节点的连接
- 如果节点是跟随者，他必须能及时的同步leader的写操作，设置超时

### kafka不同于传统消息系统的点

- kafka持久化日志，这些日志可以被重复读取和无限期保留
- kafka是一个分布式系统，它以集群的方式运行，可以灵活伸缩，在内部通过复制数据提升容错能力
- 支持实时的流式数据处理

### 消费者如何不自动提交偏移量，由应用提交？

将enable.auto.commit设置为false,然后在处理一批消息后手动提交或异步提交

### 消费者故障，出现活锁问题如何解决？

kafka 消费者正常情况下是订阅一个 topic 并且能够 poll 消息。该消费者会占用一个分区，同时需要定时向 zk 发送心跳监测，以证明自己活着。当消费者占用一个分区后，且能够正常发送心跳，但是不 pull 消息了，不再进行消息处理了，这种情况下就出现了活锁。

kafka 这边处理的时候会配置 max.pull.interval.ms 活跃监测机制。如果客户端调用 pull 的频率大于最大间隔，就会将当前客户端连接断开，让其它的消费者过来消费。

### 如何控制消费的位置

kafka使用seek(TopicPartition, long)指定新的消费位置，用于查找服务器保留的最早和最新的offset的特殊方法也可用（seekToBeginning(Collection) seekToEnd(Collection）

### kafka的高可用机制

多副本冗余的高可用机制，结合分区选举机制、消息确认机制

消费者 生产者 中间商都有多个

### Kafka如何不重复消费数据

加全局唯一ID，如果已经存在了，就可以跳过了，很简单的一个想法

### kafka为何吞吐量很高

多分区、batch send、kafka Reactor网络模型、page cache、send file零拷贝、数据压缩等

- 多分区：kafka中一个topic会被分成多个若干分区，每个分区在同一时间只会被一个消费者消费
- Bache send: 数据读写是批量的而不是单条的
- Reactor网络模型：kafka服务端与客户端的运行场景不同，面对高并发、低延迟的需求，kafka服务端使用Reactor模式是实现其网络层
- Page cache: 为了优化读写性能，kafka利用了操作系统本身的page cache，利用操作系统自身的内存而不是JVM空间内存
- send file零拷贝：零拷贝就是一种避免CPU将数据从一块存储拷贝到另一块存储的技术。linux操作系统零拷贝机制使用了sendfile方法，允许操作系统将数据从page cache直接发送到网络，避免低效的复制数据。
- 数据压缩：通过数据压缩可以加快数据读取吞吐量，但是要注意考虑解压数据的代价



















