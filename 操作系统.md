## 1. 进程和线程

进程是一组线程的集合，进程是系统分配资源的基本单位，如PCB,虚拟地址空间，创建页表，维护映射，把硬盘的代码数据加载到内存，文件描述符等。

linux下线程用进程PCB模拟描述，也叫轻量级进程，是CPU调度的基本单位。

### 进程和线程的区别

进程是一组线程的集合，进程是系统分配资源的基本单位，如PCB,虚拟地址空间，创建页表，维护映射，把硬盘的代码数据加载到内存，文件描述符等。

linux下线程用进程PCB模拟描述，也叫轻量级进程，是CPU调度的基本单位。

创建销毁线程要比创建销毁进程成本低的多。（创建进程要，创建PCB,开辟虚拟地址空间，创建页表，维护映射关系，加载硬盘数据到内存，创建文件描述符，等等，而创建线程只要创建一个PCB指向进程的虚拟地址空间即可）

进程拥有自己独立的虚拟地址空间，而一个进程中的多个线程共享进程的虚拟地址空间

线程占用的资源要比进程少，线程有私有的栈结构，保存私有的数据使线程直接不相互影响

线程缺乏访问控制，进程中的一个线程出错，会终止掉整个进程，从而导致其他线程也凉凉，而一个进程出错，不会影响另一个进程


### 应用场景区别
线程应用场景：等待慢速I/O时，交给一个线程等待，接着做其他事情；通信，比较容易（注意加锁）

进程的应用场景：需要安全稳定时用进程，需要速度时用进程，既要速度又要安全

### 一个线程会产生死锁吗？
这是可能的，因为有后台线程，例如终结器线程，该线程可以在后台运行用户代码。 这允许主线程和终结器线程彼此死锁。

## 2. 死锁
死锁产生的条件

1、互斥使用，即当资源被一个线程使用(占有)时，别的线程不能使用。

2、不可抢占，资源请求者不能强制从资源占有者手中夺取资源，资源只能由资源占有者主动释放。

3、请求和保持，即当资源请求者在请求其他的资源的同时保持对原有资源的占有。

4、循环等待，即存在一个等待队列：P1占有P2的资源，P2占有P3的资源，P3占有P1的资源。这样就形成了一个等待环路。

当上述四个条件满足时，便会产生死锁

## 3. 不同的进程中的变量地址相同，会产生问题吗？
每个进程都有自己的虚拟空间地址，这里的地址不是真正的物理地址，当你在不同的进程中看到相同的地址时，其实映射的物理地址是不一样的。
当然有一个特例，共享内存，对于共享内存的话，相同的虚拟地址会映射到同样的物理地址，减少不同进程在共享数据上保存多分同样数据的空间浪费。

## 4. 进程间通信
1. 管道，又分为无名管道和有名管道，无名管道只适合用于具有亲缘关系的诸如父子、兄弟进程间通信，数据是单向流动的，类似于队列，读空或者写满都会造成堵塞，数据存放于内存中；

有名管道是无名管道的加强版本，不仅仅适合用于具有亲缘关系的进程间通信，管道名存放于文件系统中，数据存放于实际的磁盘介质或者文件系统中。

2. 信号是Linux系统中用于进程间互相通信或者操作的一种机制，信号可以在任何时候发给某一进程，而无需知道该进程的状态。
如果该进程当前并未处于执行状态，则该信号就有内核保存起来，知道该进程回复执行并传递给它为止。
如果一个信号被进程设置为阻塞，则该信号的传递被延迟，直到其阻塞被取消是才被传递给进程。

3. 消息队列：消息队列是存放在内核中的消息链表，每个消息队列由消息队列标识符表示。
与管道（无名管道：只存在于内存中的文件；命名管道：存在于实际的磁盘介质或者文件系统）不同的是消息队列存放在内核中，只有在内核重启(即，操作系统重启)或者显示地删除一个消息队列时，该消息队列才会被真正的删除。
另外与管道不同的是，消息队列在某个进程往一个队列写入消息之前，并不需要另外某个进程在该队列上等待消息的到达。

4. 信号量：三个操作，创建，等待，挂出

5. 共享内存

6. 套接字：可以实现跨网络间不同机器间的进程间通信

## 5. 操作系统调度方式

### 一、先来先服务和短作业(进程)优先调度算法

#### FCFS

先来先服务(FCFS)调度[算法](http://lib.csdn.net/base/datastructure)是一种最简单的调度算法，该算法既可用于作业调度，也可用于进程调度。当在作业调度中采用该算法时，每次调度都是从后备作业队列中选择一个或多个最先进入该队列的作业，将它们调入内存，为它们分配资源、创建进程，然后放入就绪队列。在进程调度中采用FCFS算法时，则每次调度是从就绪队列中选择一个最先进入该队列的进程，为之分配处理机，使之投入运行。该进程一直运行到完成或发生某事件而阻塞后才放弃处理机。

#### SJF

短作业(进程)优先调度算法SJ(P)F，是指对短作业或短进程优先调度的算法。它们可以分别用于作业调度和进程调度。短作业优先(SJF)的调度算法是从后备队列中选择一个或若干个估计运行时间最短的作业，将它们调入内存运行。而短进程优先(SPF)调度算法则是从就绪队列中选出一个估计运行时间最短的进程，将处理机分配给它，使它立即执行并一直执行到完成，或发生某事件而被阻塞放弃处理机时再重新调度。

### 二、高优先权优先调度算法

#### 1．优先权调度算法的类型

为了照顾紧迫型作业，使之在进入系统后便获得优先处理，引入了最高优先权优先(FPF)调度算法。此算法常被用于批处理系统中，作为作业调度算法，也作为多种[操作系统](http://www.wypblog.com/archives/category/操作系统)中的进程调度算法，还可用于实时系统中。当把该算法用于作业调度时，系统将从后备队列中选择若干个优先权最高的作业装入内存。当用于进程调度时，该算法是把处理机分配给就绪队列中优先权最高的进程，这时，又可进一步把该算法分成如下两种。

1) 非抢占式优先权算法

在这种方式下，系统一旦把处理机分配给就绪队列中优先权最高的进程后，该进程便一直执行下去，直至完成；或因发生某事件使该进程放弃处理机时，系统方可再将处理机重新分配给另一优先权最高的进程。这种调度算法主要用于批处理系统中；也可用于某些对实时性要求不严的实时系统中。

2) 抢占式优先权调度算法

在这种方式下，系统同样是把处理机分配给优先权最高的进程，使之执行。但在其执行期间，只要又出现了另一个其优先权更高的进程，进程调度程序就立即停止当前进程(原优先权最高的进程)的执行，重新将处理机分配给新到的优先权最高的进程。因此，在采用这种调度算法时，是每当系统中出现一个新的就绪进程i 时，就将其优先权Pi与正在执行的进程j 的优先权Pj进行比较。如果Pi≤Pj，原进程Pj便继续执行；但如果是Pi>Pj，则立即停止Pj的执行，做进程切换，使i 进程投入执行。显然，这种抢占式的优先权调度算法能更好地满足紧迫作业的要求，故而常用于要求比较严格的实时系统中，以及对性能要求较高的批处理和分时系统中。

#### 2．高响应比优先调度算法

在批处理系统中，短作业优先算法是一种比较好的算法，其主要的不足之处是长作业的运行得不到保证。如果我们能为每个作业引入前面所述的动态优先权，并使作业的优先级随着等待时间的增加而以速率a 提高，则长作业在等待一定的时间后，必然有机会分配到处理机。该优先权的变化规律可描述为：
由于等待时间与服务时间之和就是系统对该作业的响应时间，故该优先权又相当于响应比RP。据此，又可表示为：
由上式可以看出：

(1) 如果作业的等待时间相同，则要求服务的时间愈短，其优先权愈高，因而该算法有利于短作业。

(2) 当要求服务的时间相同时，作业的优先权决定于其等待时间，等待时间愈长，其优先权愈高，因而它实现的是先来先服务。

(3) 对于长作业，作业的优先级可以随等待时间的增加而提高，当其等待时间足够长时，其优先级便可升到很高，从而也可获得处理机。简言之，该算法既照顾了短作业，又考虑了作业到达的先后次序，不会使长作业长期得不到服务。因此，该算法实现了一种较好的折衷。当然，在利用该算法时，每要进行调度之前，都须先做响应比的计算，这会增加系统开销。

### 三、基于时间片的轮转调度算法

#### 1．时间片轮转法

1) 基本原理

在早期的时间片轮转法中，系统将所有的就绪进程按先来先服务的原则排成一个队列，每次调度时，把CPU 分配给队首进程，并令其执行一个时间片。时间片的大小从几ms 到几百ms。当执行的时间片用完时，由一个计时器发出时钟中断请求，调度程序便据此信号来停止该进程的执行，并将它送往就绪队列的末尾；然后，再把处理机分配给就绪队列中新的队首进程，同时也让它执行一个时间片。这样就可以保证就绪队列中的所有进程在一给定的时间内均能获得一时间片的处理机执行时间。换言之，系统能在给定的时间内响应所有用户的请求。

#### 2．多级反馈队列调度算法

前面介绍的各种用作进程调度的算法都有一定的局限性。如短进程优先的调度算法，仅照顾了短进程而忽略了长进程，而且如果并未指明进程的长度，则短进程优先和基于进程长度的抢占式调度算法都将无法使用。而多级反馈队列调度算法则不必事先知道各种进程所需的执行时间，而且还可以满足各种类型进程的需要，因而它是目前被公认的一种较好的进程调度算法。在采用多级反馈队列调度算法的系统中，调度算法的实施过程如下所述。

(1) 应设置多个就绪队列，并为各个队列赋予不同的优先级。第一个队列的优先级最高，第二个队列次之，其余各队列的优先权逐个降低。该算法赋予各个队列中进程执行时间片的大小也各不相同，在优先权愈高的队列中，为每个进程所规定的执行时间片就愈小。例如，第二个队列的时间片要比第一个队列的时间片长一倍，……，第i+1个队列的时间片要比第i个队列的时间片长一倍。

(2) 当一个新进程进入内存后，首先将它放入第一队列的末尾，按FCFS原则排队等待调度。当轮到该进程执行时，如它能在该时间片内完成，便可准备撤离系统；如果它在一个时间片结束时尚未完成，调度程序便将该进程转入第二队列的末尾，再同样地按FCFS原则等待调度执行；如果它在第二队列中运行一个时间片后仍未完成，再依次将它放入第三队列，……，如此下去，当一个长作业(进程)从第一队列依次降到第*n*队列后，在第*n* 队列便采取按时间片轮转的方式运行。

(3) 仅当第一队列空闲时，调度程序才调度第二队列中的进程运行；仅当第1～(i-1)队列均空时，才会调度第i队列中的进程运行。如果处理机正在第i队列中为某进程服务时，又有新进程进入优先权较高的队列(第1～(i-1)中的任何一个队列)，则此时新进程将抢占正在运行进程的处理机，即由调度程序把正在运行的进程放回到第i队列的末尾，把处理机分配给新到的高优先权进程。

## 6. 内存管理机制和python垃圾回收机制

### 什么是分页机制

逻辑地址和物理地址分离的内存分配管理方案

程序的逻辑地址划分固定大小的页
物理地址划分为同样大小的帧
通过页表和对应逻辑地址和物理地址

### 什么是分段机制

分段是为了满足代码的一些逻辑需求

数据共享、数据保护、动态链接
通过短标来对应逻辑地址和物理地址
每个段内部是连续的内存分配，段和段之间是离散分配的

### 分段和分页的区别

页是出于内存利用率的角度提出的离散分配机制
段是出于用户的角度，用于数据保护，数据隔离等用途的管理机制
页的大小是固定的，操作系统决定；段大小不确定，用户程序确定

### 什么是虚拟内存

通过把一部分暂时不用的内存信息放到硬盘上

局部性原理，程序运行时只有部分必要的信息装入内存
内存中暂时不需要的内容放到硬盘上
系统似乎提供了比实际内存大得多的容量，称之为虚拟内存

### 虚拟地址和物理地址转换

答：32位的虚拟地址被分成3个域，目录（10位），页表（10位），偏移（12位）

从CR3找到我们的页目录地址
根据目录的10位，找到页目录
根据页表10位，找到目的页表，页的起始的地址
加上偏移的12位，找到目的地址

### 什么是内存抖动

本质上是频繁的页调度行为

频繁的页调度，进程不断产生缺页中断
置换了一个页，又不断再次需要这个页
运行的程序太多;页面替换策略不好，终止进程或增加物理内存

### Python垃圾回收机制原理

python无需我们手动回收内存

python内存垃圾回收以引用计数为主（缺点：循环引用无法解决），采用引用标记清除来解决引用计数所存在的循环引用问题，最后通过分代回收算法来提高垃圾回收的效率。

## 7. 两种IO多路复用的事件处理模式

### Proactor模式和Reactor模式的区别？

**事件处理模式：Reactor模式（同步IO）/Proactor模式（异步IO）。**
服务器程序通常要处理3类事件，I/O事件、信号和定时事件。在处理事件上有两种高效的事件处理模式：Reactor和Proactor。这两种其实也都是I/O复用模型。
Reactor：它要求主线程只负责监听文件描述上是否有事件发生，有的话就立即将该事件通知工作线程。除此之外，主线程不做任何其他实质性的工作，读写数据、接收新的连接，以及处理客户请求均在工作线程中完成。使用同步I/O模型（以epoll_wait()为例）实现的**Reactor模式的工作流程如下：**
1）主线程往epoll内核事件表中注册socket上的读就绪事件。
2）主线程调用epoll_wait()等待socket上有数据可读。
3）当socket上有数据可读时，epoll_wait()通知主线程。主线程将socket可读事件放入请求队列。
4）睡眠在请求队列上的某个工作线程被唤醒，它从socket读取数据，并处理客户请求，然后往epoll内核事件表中注册该socket上的写事件。
5）主线程调用epoll_wait()等待socket可写。
6）当socket可写时，epoll_wait()通知主线程。主线程将socket可写事件放入请求队列。
7）睡眠在请求队列上的某个工作线程被唤醒，它往socket上写入服务器处理客户请求的结果。
**Proactor模式：**与Reactor模式不同，Proactor模式将所有I/O操作都交给主线程和内核来处理，工作线程仅仅负责业务逻辑。使用异步I/O模型（aio_read和aio_write为例）实现的Proactor模式工作流程：
1）主线程调用aio_read函数向内核注册socket上的读完成事件，并告诉内核用户读缓冲区的位置，以及读操作完成时如何通知应用程序。（信号）
2）主线程继续处理其他逻辑。
3）应用程序预先定义好的信号处理函数选择一个工作线程来处理客户请求。工作线程处理完客户请求之后，调用aio_write函数向内核注册socket上的写完成事件，并告诉内核用户缓冲区的位置，以及写操作完成时如何通知应用程序（信号）。
4）主线程继续处理其他逻辑。
5）当用户缓冲区的数据被写入socket之后，内核将向应用程序发送一个信号，以通知应用程序数据已经发送完毕。
6）应用程序预先定义好的信号处理函数选择一个工作线程来做善后处理，比如决定是否关闭socket。
**同步模拟Proactor模型：**《Linux高性能服务器编程》一书中提到了一种用同步I/O来模拟Proactor模式的方法。其原理是：主线程执行数据读写操作，读写完成之后，主线程向工作线程通知这一“完成事件”。那么工作线程直接获得了读写结果，接下来只要做的只是对读写结果的处理。
1）主线程调用epoll_wait()内核事件表中注册socket上的读就绪事件。
2）主线程调用epoll_wait()等待socket上有数据可读。
3）当socket上有数据可读时，epoll_wait()通知主线程。主线程从socket循环读取数据，直到没有更多数据可读，然后将所有数据封装成一个请求对象并插入请求队列。
4）睡眠在请求队列中的某个工作流程被唤醒，它获得请求对象并处理客户请求，然后往epoll内核事件表中注册socket上的写就绪事件。
5）主线程调用epoll_wait()等待socket可写。
6）当socket可写时，epoll_wait()通知主线程。主线程往socket上写入服务器处理客户请求的结果。
这里同步模拟和异步模拟Proactor的区别在于，同步模拟是主线程自己进行I/O操作，需要等待读完数据，而异步I/O是通过aio_read()异步读取，主线程不需要等待I/O完成。
总结：Reactor和Proactor的本质区别在于谁负责I/O操作，其实它们都可以分别利用同步I/O或者异步I/O来实现。

**简单的理解：首先它们都是IO复用下的事件驱动模型，然后就从同步异步这两个点来切入概念。注意关键区别在于何时IO，reactor是关心就绪事件，比如可读了，就通知你，就像epoll_wait 。proactor关心的是完成比如读完了，就通知你。**

## 8. epoll， poll，selector以及三者之间的区别

(1)select==>时间复杂度O(n)

它仅仅知道了，有I/O事件发生了，却并不知道是哪那几个流（可能有一个，多个，甚至全部），我们只能无差别轮询所有流，找出能读出数据，或者写入数据的流，对他们进行操作。所以**select具有O(n)的无差别轮询复杂度**，同时处理的流越多，无差别轮询时间就越长。

(2)poll==>时间复杂度O(n)

poll本质上和select没有区别，它将用户传入的数组拷贝到内核空间，然后查询每个fd对应的设备状态， **但是它没有最大连接数的限制**，原因是它是基于链表来存储的.

(3)epoll==>时间复杂度O(1)

**epoll可以理解为event poll**，不同于忙轮询和无差别轮询，epoll会把哪个流发生了怎样的I/O事件通知我们。所以我们说epoll实际上是**事件驱动（每个事件关联上fd）**的，此时我们对这些流的操作都是有意义的。**（复杂度降低到了O(1)）**

select，poll，epoll都是IO多路复用的机制。I/O多路复用就通过一种机制，可以监视多个描述符，一旦某个描述符就绪（一般是读就绪或者写就绪），能够通知程序进行相应的读写操作。**但select，poll，epoll本质上都是同步I/O，因为他们都需要在读写事件就绪后自己负责进行读写，也就是说这个读写过程是阻塞的**，而异步I/O则无需自己负责进行读写，异步I/O的实现会负责把数据从内核拷贝到用户空间。 

epoll跟select都能提供多路I/O复用的解决方案。在现在的Linux内核里有都能够支持，其中epoll是Linux所特有，而select则应该是POSIX所规定，一般操作系统均有实现

**select：**

select本质上是通过设置或者检查存放fd标志位的数据结构来进行下一步处理。这样所带来的缺点是：

1、 单个进程可监视的fd数量被限制，即能监听端口的大小有限。

   一般来说这个数目和系统内存关系很大，具体数目可以cat /proc/sys/fs/file-max察看。32位机默认是1024个。64位机默认是2048.

2、 对socket进行扫描时是线性扫描，即采用轮询的方法，效率较低：

​    当套接字比较多的时候，每次select()都要通过遍历FD_SETSIZE个Socket来完成调度,不管哪个Socket是活跃的,都遍历一遍。这会浪费很多CPU时间。如果能给套接字注册某个回调函数，当他们活跃时，自动完成相关操作，那就避免了轮询，这正是epoll与kqueue做的。

3、需要维护一个用来存放大量fd的数据结构，这样会使得用户空间和内核空间在传递该结构时复制开销大

**poll：**

poll本质上和select没有区别，它将用户传入的数组拷贝到内核空间，然后查询每个fd对应的设备状态，如果设备就绪则在设备等待队列中加入一项并继续遍历，如果遍历完所有fd后没有发现就绪设备，则挂起当前进程，直到设备就绪或者主动超时，被唤醒后它又要再次遍历fd。这个过程经历了多次无谓的遍历。

**它没有最大连接数的限制**，原因是它是基于链表来存储的，但是同样有一个缺点：

1、大量的fd的数组被整体复制于用户态和内核地址空间之间，而不管这样的复制是不是有意义。          

2、poll还有一个特点是“水平触发”，如果报告了fd后，没有被处理，那么下次poll时会再次报告该fd。

**epoll:**

epoll有EPOLLLT和EPOLLET两种触发模式，LT是默认的模式，ET是“高速”模式。LT模式下，只要这个fd还有数据可读，每次 epoll_wait都会返回它的事件，提醒用户程序去操作，而在ET（边缘触发）模式中，它只会提示一次，直到下次再有数据流入之前都不会再提示了，无 论fd中是否还有数据可读。所以在ET模式下，read一个fd的时候一定要把它的buffer读光，也就是说一直读到read的返回值小于请求值，或者 遇到EAGAIN错误。还有一个特点是，epoll使用“事件”的就绪通知方式，通过epoll_ctl注册fd，一旦该fd就绪，内核就会采用类似callback的回调机制来激活该fd，epoll_wait便可以收到通知。

**epoll为什么要有EPOLLET触发模式？**

如果采用EPOLLLT模式的话，系统中一旦有大量你不需要读写的就绪文件描述符，它们每次调用epoll_wait都会返回，这样会大大降低处理程序检索自己关心的就绪文件描述符的效率.。而采用EPOLLET这种边沿触发模式的话，当被监控的文件描述符上有可读写事件发生时，epoll_wait()会通知处理程序去读写。如果这次没有把数据全部读写完(如读写缓冲区太小)，那么下次调用epoll_wait()时，它不会通知你，也就是它只会通知你一次，直到该文件描述符上出现第二次可读写事件才会通知你！！！**这种模式比水平触发效率高，系统不会充斥大量你不关心的就绪文件描述符**

**epoll的优点：**

1、**没有最大并发连接的限制，能打开的FD的上限远大于1024（1G的内存上能监听约10万个端口）**；
**2、效率提升，不是轮询的方式，不会随着FD数目的增加效率下降。只有活跃可用的FD才会调用callback函数；**
**即Epoll最大的优点就在于它只管你“活跃”的连接，而跟连接总数无关，因此在实际的网络环境中，Epoll的效率就会远远高于select和poll。**

3、 内存拷贝，利用mmap()文件映射内存加速与内核空间的消息传递；即epoll使用mmap减少复制开销。
**select、poll、epoll 区别总结：**

1、支持一个进程所能打开的最大连接数

select

单个进程所能打开的最大连接数有FD_SETSIZE宏定义，其大小是32个整数的大小（在32位的机器上，大小就是32*32，同理64位机器上FD_SETSIZE为32*64），当然我们可以对进行修改，然后重新编译内核，但是性能可能会受到影响，这需要进一步的测试。

poll

poll本质上和select没有区别，但是它没有最大连接数的限制，原因是它是基于链表来存储的

epoll

虽然连接数有上限，但是很大，1G内存的机器上可以打开10万左右的连接，2G内存的机器可以打开20万左右的连接

2、FD剧增后带来的IO效率问题

select

因为每次调用时都会对连接进行线性遍历，所以随着FD的增加会造成遍历速度慢的“线性下降性能问题”。

poll

同上

epoll

因为epoll内核中实现是根据每个fd上的callback函数来实现的，只有活跃的socket才会主动调用callback，所以在活跃socket较少的情况下，使用epoll没有前面两者的线性下降的性能问题，但是所有socket都很活跃的情况下，可能会有性能问题。

3、 消息传递方式

select

内核需要将消息传递到用户空间，都需要内核拷贝动作

poll

同上

epoll

epoll通过内核和用户空间共享一块内存来实现的。

**总结：**

**综上，在选择select，p****oll，epoll时要根据具体的使用场合以及这三种方式的自身特点。**

**1、表面上看epoll的性能最好，但是在连接数少并且连接都十分活跃的情况下，select和poll的性能可能比epoll好，毕竟epoll的通知机制需要很多函数回调。**

**2、select低效是因为每次它都需要轮询。但低效也是相对的，视情况而定，也可通过良好的设计改善** 

## 9. 内存多线程安全问题

### 对一块内存1，值为a。线程1：将该内存的值修改为b：a->b。线程2：a->c，c->a。如何避免当内存值a被修改为c之后，线程1修改为b。
可以使用CAS（比较与交换，Compare and swap）算法来解决，它是一种有名的无锁算法，使用方法很简单，每次去检测一个值是不是目标值是则修改为某一个值，否则不做处理，这整个操作是原子的。这个场景中我们只需要在线程1中使用这个算法即可保证内存被修改为c的时候，线程1不修改内存的值。



​	



   


